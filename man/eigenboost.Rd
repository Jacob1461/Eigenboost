% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/eigenboost.R
\name{eigenboost}
\alias{eigenboost}
\title{Adaboost on reflected datasets}
\usage{
eigenboost(
  X,
  y,
  n_rounds = 10,
  reflection_every = 3,
  verbose = FALSE,
  control = NULL,
  reflections_type = "eigen",
  tree_depth = 1
)
}
\arguments{
\item{X}{A dataframe or matrix of predictors values.}

\item{y}{A response vector of 1 or -1.}

\item{n_rounds}{The number of trees in the ensemble.}

\item{reflection_every}{Perform a Dataset reflection every this many rounds.}

\item{verbose}{Print additional output.}

\item{control}{Additional settings for the CART trees}

\item{reflections_type}{The type of Dataset reflection to perform.}

\item{tree_depth}{The max depth of the CART trees.}
}
\value{
Returns a eigenboost object containing the alpha values for each tree,
each tree object, the householder matrix corresponding to that tree.
}
\description{
An implementation of adaboost using eigenvector based dataset reflections
using PCA and householder matrices.
}
\note{
Adaboost code adapted from JOUSboost implementation.
}
\examples{
\dontrun{
  set.seed(123)

# Make iris into a binary class classification dataset
iris2 <- iris[iris$Species != "setosa", ]
rownames(iris2) <- NULL
iris2$Species <- ifelse(iris2$Species == "versicolor", 1, -1)

# Make training and testing splits
train_indx <- sample(nrow(iris2), 65)
X_train <- iris2[train_indx, 1:4]
y_train <- as.numeric(iris2$Species[train_indx])
X_test <- iris2[-train_indx, 1:4]
y_test <- as.numeric(iris2$Species[-train_indx])

# Fit model
model <- eigenboost(X = X_train, y = y_train, tree_depth = 1)

# Make predictions
preds <- predict.eigenboost(model, X_test)

# Evaluate
accuracy <- mean(preds == y_test)
print(accuracy)
}
}
\references{
Freund, Y. and Schapire, R. (1997). A decision-theoretic
generalization of online learning and an application to boosting, Journal of
 Computer and System Sciences 55: 119-139.
}
